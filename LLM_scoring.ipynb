{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9572f0472f4c7ae1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:16:47.280352Z",
     "start_time": "2024-12-01T20:16:33.348660Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %pip install pydantic openai tqdm pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5153a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b8aa3bd04574a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:37:29.151905Z",
     "start_time": "2024-12-03T21:37:26.489135Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Literal\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfb51906357354",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:37:33.744041Z",
     "start_time": "2024-12-03T21:37:33.740468Z"
    }
   },
   "outputs": [],
   "source": [
    "api_key = '<api_key>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9e0109b5c27fdd35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T21:37:35.424752Z",
     "start_time": "2024-12-03T21:37:34.695596Z"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a8f8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str=\"gpt-4o-2024-11-20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6483e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Ты выступаешь в роли судьи для оценки качества генерации текста заключения офтальмолога, созданного языковой моделью на основании параметров глазного дна. Проверь ответ по четырём критериям, выстави оценки и обоснуй их.\n",
    "\n",
    "**Входные данные:**\n",
    "- JSON с исходными параметрами глазного дна\n",
    "- Текстовое описание, сгенерированное языковой моделью\n",
    "\n",
    "---\n",
    "\n",
    "**Критерий №1: Совпадение входных параметров с текстовым описанием**  \n",
    "Проверь, чтобы каждый параметр из JSON был верно отражён в тексте. Допускается перефразирование (например, «нормальный» → «нормального»).\n",
    "\n",
    "**Оценка:**  \n",
    "- 1 балл — все параметры отражены корректно, без расхождений  \n",
    "- 0 баллов — есть хотя бы одно расхождение\n",
    "\n",
    "Приведи пример расхождения при оценке 0.\n",
    "\n",
    "---\n",
    "\n",
    "**Критерий №2: Отсутствие вводных конструкций и лишних фраз**  \n",
    "Текст должен содержать только медицинское описание. Не допускаются вводные конструкции или пояснительные фразы (например: «в данном случае», «следует отметить», «как известно» и т.п.), а также фразы от языковой модели (например: «конечно», «текст описания» и т.п.).\n",
    "\n",
    "**Оценка:**  \n",
    "- 1 балл — нет вводных конструкций  \n",
    "- 0 баллов — есть хотя бы одна\n",
    "\n",
    "Приведи пример лишней фразы при оценке 0.\n",
    "\n",
    "---\n",
    "\n",
    "**Критерий №3: Соблюдение порядка описания структур**  \n",
    "Порядок должен быть следующим:\n",
    "\n",
    "1. **Диск зрительного нерва (ДЗН)**  \n",
    "   - Цвет  \n",
    "   - Монотонность окраски  \n",
    "   - Размер  \n",
    "   - Форма  \n",
    "   - Границы  \n",
    "\n",
    "2. **Экскавация ДЗН**  \n",
    "   - Размер экскавации  \n",
    "   - Положение экскавации  \n",
    "   - Сосудистый пучок  \n",
    "   - Патологические изменения (при наличии)\n",
    "\n",
    "3. **Сосуды глазного дна**  \n",
    "   - Ход  \n",
    "   - Извитость  \n",
    "   - Бифуркация  \n",
    "   - Калибр  \n",
    "   - А/В индекс  \n",
    "   - Патологии (если есть)\n",
    "\n",
    "4. **Макула**  \n",
    "   - Макулярный рефлекс  \n",
    "   - Фовеолярный рефлекс\n",
    "\n",
    "5. **Периферия глазного дна**  \n",
    "   - Только патологические изменения (если есть)\n",
    "\n",
    "**Оценка:**  \n",
    "- 1 балл — порядок строго соблюдён  \n",
    "- 0 баллов — есть отклонения\n",
    "\n",
    "Укажи, где нарушен порядок при оценке 0.\n",
    "\n",
    "---\n",
    "\n",
    "**Критерий №4: Плавность и естественность языка**  \n",
    "Оцени текст с точки зрения профессионального языка врача-офтальмолога.\n",
    "\n",
    "**Оценка:**  \n",
    "От 0 (очень неестественно) до 5 (максимально естественно и профессионально)\n",
    "\n",
    "Кратко обоснуй оценку, указав стилистически слабые места, если есть.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e87666241c2411d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T21:25:52.060480Z",
     "start_time": "2024-12-01T21:25:52.017852Z"
    }
   },
   "outputs": [],
   "source": [
    "class EvaluationResult(BaseModel):\n",
    "    param_match_score: Literal[0, 1] = Field(..., description=\"1, если все параметры из JSON корректно отражены в тексте; 0, если есть хотя бы одно расхождение\")\n",
    "    no_intro_phrases_score: Literal[0, 1] = Field(..., description=\"1, если в тексте нет вводных конструкций и лишних фраз; 0 — если есть хотя бы одна\")\n",
    "    structure_order_score: Literal[0, 1] = Field(..., description=\"1, если порядок описания структур соблюдён строго; 0 — если есть отклонения\")\n",
    "    language_naturalness_score: Literal[0, 1, 2, 3, 4, 5] = Field(..., description=\"Оценка от 0 до 5 за плавность и естественность медицинского языка\")\n",
    "\n",
    "    param_match_comment: str = Field(..., description=\"Комментарий к оценке по параметрам; указать пример несоответствия при необходимости\")\n",
    "    no_intro_phrases_comment: str = Field(..., description=\"Комментарий к оценке по вводным конструкциям; привести пример при необходимости\")\n",
    "    structure_order_comment: str = Field(..., description=\"Комментарий к оценке порядка структур; указать, где нарушен порядок при необходимости\")\n",
    "    language_naturalness_comment: str = Field(..., description=\"Комментарий к оценке плавности и естественности языка; обосновать балл\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42bc70f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"TEST_prompts.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    loaded_samples = json.load(f)\n",
    "\n",
    "len(loaded_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8dbcf",
   "metadata": {},
   "source": [
    "## **Scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab2ae411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(data_path, type):\n",
    "    df = pd.read_csv(data_path)\n",
    "    texts = df['text']\n",
    "\n",
    "    data = [(loaded_samples[i], texts[i]) for i in range(len(loaded_samples))]\n",
    "\n",
    "    dataframe_elements = []\n",
    "\n",
    "    for item in data:\n",
    "        json_data = item[0]\n",
    "        llm_text = item[1]\n",
    "\n",
    "        user_prompt = f\"\"\"Исходный JSON:\n",
    "    {json_data}\n",
    "\n",
    "    Сгенерированный текст:\n",
    "    {llm_text}\n",
    "    \"\"\"\n",
    "\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model_str,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            response_format=EvaluationResult,\n",
    "        )\n",
    "\n",
    "        json_answer = completion.choices[0].message.content\n",
    "        llm_dict = json.loads(json_answer)\n",
    "        dataframe_elements.append(llm_dict)\n",
    "\n",
    "    df = pd.DataFrame(dataframe_elements)\n",
    "    df.to_csv(f\"scores/{type}_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71e69181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('data/BioMistal_data.csv', 'BioMistral')\n",
      "('data/RuAdapt_data.csv', 'RuAdapt')\n",
      "('data/Saiga_data.csv', 'Saiga')\n",
      "('data/Yandex_data.csv', 'Yandex')\n",
      "('data/TableLlama_data.csv', 'TableLlama')\n"
     ]
    }
   ],
   "source": [
    "scoring_metas = [\n",
    "    ('data/BioMistal_data.csv', 'BioMistral'),\n",
    "    ('data/RuAdapt_data.csv', 'RuAdapt'),\n",
    "    ('data/Saiga_data.csv', 'Saiga'),\n",
    "    ('data/Yandex_data.csv', 'Yandex'),\n",
    "    ('data/TableLlama_data.csv', 'TableLlama'),\n",
    "]\n",
    "\n",
    "for meta in scoring_metas:\n",
    "    print(meta)\n",
    "    scoring_function(meta[0], meta[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
